---
title: "6.L3"
author: "Sara Knox"
date: "04/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())

library(plotly)
#library(readxl)
library(tidyverse)
library(caret)
library(lubridate)
library(REddyProc)
library(tidyverse)
library(dplyr)

# set wd
getwd()
#dir <- "../Flux-tower/"
dir <- "/Users/marionnyberg/Google\ Drive/Micromet\ Lab/Projects/2019-Burns\ Bog\ 2/Flux-tower"
knitr::opts_knit$set(root.dir = dir)
```

```{r Load data, echo=FALSE, include=FALSE}
EddyData.F <- fLoadTXTIntoDataframe("./flux_data/REddyProc_input/for_gap_filling_partitioningBB2.txt")


```

```{r Gap-fill and partition in REddyProc, echo=FALSE, include=FALSE}
# Add time stamp in POSIX time format -------------------------------------
EddyDataWithPosix.F <- fConvertTimeToPosix(EddyData.F, 'YDH',Year.s = 'Year',Day.s = 'DoY',Hour.s = 'Hour')

#EddyDataWithPosix.F <-EddyDataWithPosix.F %>% filter(DateTime >="2020-01-01 00:00:00") # added by marion for thesis

# Initalize R5 reference class sEddyProc for post-processing of eddy data with the variables needed for post-processing later -------------------------------------
EddyProc.C <- sEddyProc$new('CA-BB', EddyDataWithPosix.F,
														c("NEE","FCH4","LE","H","Rg","Tair",'Tsoil5cm_1','Tsoil10cm_1','Tsoil30cm_1','Tsoil50cm_1','Tsoil5cm_2','Tsoil10cm_2','Tsoil30cm_2','Tsoil50cm_2', 'Tsoil5cm_3','Tsoil10cm_3','Tsoil30cm_3','Tsoil50cm_3',"rH","VPD","Ustar","WTH"))

uStarTh <- EddyProc.C$sEstUstarThresholdDistribution(nSample = 100L, probs = c(0.05, 0.5, 0.95)) #added 14/12/2020 M.Nyberg
uStarTh %>%
  filter( aggregationMode == "year") %>%
  select( uStar, "5%", "50%", "95%") #added 14/12/2020 M.Nyberg

uStarThAnnual <-usGetAnnualSeasonUStarMap(uStarTh)[-2] #added 14/12/2020 M.Nyberg
uStarSuffixes <- colnames(uStarThAnnual)[-1] #added 14/12/2020 M.Nyberg
print(uStarThAnnual) #added 14/12/2020 M.Nyberg

EddyProc.C$sGetUstarScenarios() #added 22/03/2021 M.Nyberg
EddyProc.C$sMDSGapFillUStarScens('NEE', FillAll = TRUE) #added M.Nyberg 26/03/2021
EddyProc.C$sMDSGapFillUStarScens('FCH4', FillAll = TRUE) #added M.Nyberg 26/03/2021


grep("NEE_.*_f$",names(EddyProc.C$sExportResults()) #added M.Nyberg 26/03/2021
, value = TRUE)
grep("NEE_.*_fsd$",names(EddyProc.C$sExportResults()) #added M.Nyberg 26/03/2021
, value = TRUE)



# Use MDS for gap-filling NEE, H, LE, and FCH4 (but also use RF for FCH4) ----------------------------------
EddyProc.C$sMDSGapFill('NEE', FillAll.b = TRUE)
EddyProc.C$sMDSGapFill('LE', FillAll.b = TRUE)
EddyProc.C$sMDSGapFill('H', FillAll.b = TRUE)
EddyProc.C$sMDSGapFill('FCH4', FillAll.b = TRUE)



# Gap-filling met data for partitioning  ----------------------------------
EddyProc.C$sSetLocationInfo(Lat_deg.n = 49.118981, Long_deg.n = -122.995150, TimeZone_h.n = -8)
EddyProc.C$sMDSGapFill('Tair', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('VPD', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Rg', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('WTH', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil5cm_1', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil10cm_1', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil30cm_1', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil50cm_1', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil5cm_2', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil10cm_2', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil30cm_2', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil50cm_2', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil5cm_3', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil10cm_3', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil30cm_3', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Tsoil50cm_3', FillAll.b = FALSE)


# Apply nighttime gap-filling algorithm -----------------------------------
EddyProc.C$sMRFluxPartition()

resP <- lapply(uStarSuffixes, function(suffix){ #added M.Nyberg 26/03/2021
EddyProc.C$sMRFluxPartition(Suffix.s = suffix)
})

grep("GPP.*_f$|Reco", #added M.Nyberg 26/03/2021
names(EddyProc.C$sExportResults()), value = TRUE)

#EddyProc.C$sApplyUStarScen(EddyProc.C$sMRFluxPartition )


# Apply daytime gap-filling algorithm -----------------------------------
EddyProc.C$sGLFluxPartition()

dayP <- lapply(uStarSuffixes, function(suffix){ #added M.Nyberg 26/03/2021
EddyProc.C$sGLFluxPartition(Suffix.s = suffix)
})

grep("GPP.*_f$|Reco|", #added M.Nyberg 26/03/2021
names(EddyProc.C$sExportResults()), value = TRUE)


# Output results -----------------------------------

FilledEddyData.F <- EddyProc.C$sExportResults()
FilledEddyData.F <- FilledEddyData.F %>% filter(season == "2020003" |season == "2020006" | season == "2020009" | season == "2020012")
names(FilledEddyData.F)

#### Using tutorial from https://cran.r-project.org/web/packages/REddyProc/vignettes/aggUncertainty.html
#1st to calculate random uncertainty
summary(FilledEddyData.F$NEE_uStar_fsd)
FilledEddyData.F %>% filter(NEE_uStar_fqc == 0) %>% summarise(
  nRec = sum(is.finite(NEE_uStar_f))
  , varSum = sum(NEE_uStar_fsd^2, na.rm = TRUE)
  , seMean = sqrt(varSum) / nRec
  , seMeanApprox = mean(NEE_uStar_fsd, na.rma = TRUE) / sqrt(nRec)
  ) %>% select(nRec, seMean, seMeanApprox)

FilledEddyData.F <- EddyProc.C$sExportResults() %>% 
  mutate(
    resid = ifelse(NEE_uStar_fqc == 0, NEE_uStar_orig - NEE_uStar_fall, NA )
  )

acf(FilledEddyData.F$resid, na.action = na.pass, main = "")

library(lognorm)
autoCorr <- computeEffectiveAutoCorr(FilledEddyData.F$resid)
nEff <- computeEffectiveNumObs(FilledEddyData.F$resid, na.rm = TRUE)
c( nEff = nEff, nObs = sum(is.finite(FilledEddyData.F$resid)))

FilledEddyData.F %>% filter(NEE_uStar_fqc == 0) %>% summarise(
  nRec = sum(is.finite(NEE_uStar_fsd))
  , varMean = sum(NEE_uStar_fsd^2, na.rm = TRUE) / nRec / (!!nEff - 1)
  , seMean = sqrt(varMean) 
  #, seMean2 = sqrt(mean(NEE_uStar_fsd^2, na.rm = TRUE)) / sqrt(!!nEff - 1)
  , seMeanApprox = mean(NEE_uStar_fsd, na.rm = TRUE) / sqrt(!!nEff - 1)
  ) %>% select(seMean, seMeanApprox)

FilledEddyData.F <- FilledEddyData.F %>% mutate(
  DateTime = EddyDataWithPosix.F$DateTime
  , DoY = as.POSIXlt(DateTime - 15*60)$yday # midnight belongs to the previous
)

NEEAggCO2 <- sapply( uStarSuffixes, function(suffix) {
    NEEHalfHour <- FilledEddyData.F[[paste0("NEE_",suffix,"_f")]]
    mean(NEEHalfHour, na.rm = TRUE)
})
molarMass <- 12.011
NEEAgg <- NEEAggCO2 * 1e-6 * molarMass * 3600*24*365.25
print(NEEAgg)

NEE_ustar_f <- (mean(FilledEddyData.F$NEE_uStar_f, na.rm = TRUE))* 1e-6 * molarMass * 3600*24*365.25

(max(NEEAgg) - min(NEEAgg)) / NEE_ustar_f # Relative error 
(max(NEEAgg) - min(NEEAgg)) / median(NEEAgg) 

0.0392 * 1e-6 * molarMass * 3600*24*365.25 # Random uncertainty from https://cran.r-project.org/web/packages/REddyProc/vignettes/aggUncertainty.html


GPPAggCO2 <- sapply( uStarSuffixes, function(suffix) { #this calculates the mean GPP across the year
    GPPHalfHour <- FilledEddyData.F[[paste0("GPP_",suffix,"_f")]]
    mean(GPPHalfHour, na.rm = TRUE)
})
molarMass <- 12.011
GPPAgg <- GPPAggCO2 * 1e-6 * molarMass * 3600*24*365.25 #converts to g C
print(GPPAgg)

((max(GPPAgg) - min(GPPAgg)) / median(GPPAgg) 

RecoAggCO2 <- sapply( uStarSuffixes, function(suffix) {
    RecoHalfHour <- FilledEddyData.F[[paste0("Reco_",suffix)]]
    mean(RecoHalfHour, na.rm = TRUE)
})
molarMass <- 12.011
RecoAgg <- RecoAggCO2 * 1e-6 * molarMass * 3600*24*365.25
print(RecoAgg)

(max(RecoAgg) - min(RecoAgg)) / median(RecoAgg) 

write.csv(FilledEddyData.F, '/Users/marionnyberg/Google\ Drive/Micromet\ Lab/Projects/2019-Burns\ Bog\ 2/Flux-tower/flux_data/FilledEddyData.csv')
```

```{r Gap-fill and partition in REddyProc, echo=FALSE, include=FALSE}
# Plot results -----------------------------------

# daily sums (from REddyProc) - CHECK UNITS!
#setwd("./flux_data")
setwd("/Users/marionnyberg/Google\ Drive/Micromet\ Lab/Projects/2019-Burns\ Bog\ 2/Flux-tower/flux_data")
EddyProc.C$sPlotDailySums(Var.s = 'LE_f',Format.s = "png", unit.s = "MJ/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'H_f',Format.s = "png", unit.s = "MJ/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'NEE_f',Format.s = "png", unit.s = "gC/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'FCH4_f',Format.s = "png", unit.s = "gC/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'GPP_f',Format.s = "png", unit.s = "gC/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'Reco',Format.s = "png", unit.s = "gC/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'GPP_DT',Format.s = "png", unit.s = "gC/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'Reco_DT',Format.s = "png", unit.s = "gC/m2/day")

# Could create other plots to check the results
#....

```

```{r Save full REddyPro output, echo=FALSE, include=FALSE}
write_csv(FilledEddyData.F,"/Users/marionnyberg/Google\ Drive/Micromet\ Lab/Projects/2019-Burns\ Bog\ 2/Flux-tower/flux_data/BB_REddyProc_gapfilled_partition_fulloutputBB2.csv")
```

```{r Save only essential variables, echo=FALSE, include=FALSE}
essential_variables <- grep("NEE_f$|NEE_fsd$|GPP_f$|GPP_DT.*$|Reco|Reco_DT.*$|LE_f$|LE_fsd$|H_f$|H_fsd$|FCH4_f$|FCH4_fsd$|NEE_uStar_f|NEE_U05_f|NEE_U50_f|NEE_U95_f|NEE_uStar_fsd|NEE_U05_fsd|NEE_U50_fsd|NEE_U95_fsd",
														names(EddyProc.C$sExportResults()), value = TRUE)
essential_variables

# Remove WTH
essential_variables <- str_remove(essential_variables, "WTH_.*")
essential_variables

essential <- FilledEddyData.F[,which(names(FilledEddyData.F) %in% essential_variables)]
```

```{r gap-fill FCH4 using random forest from Kim et al. 2019, echo=FALSE, include=FALSE}

# variable we need for FCH4 gap-filling
Input <- read.table("/Users/marionnyberg/Google\ Drive/Micromet\ Lab/Projects/2019-Burns\ Bog\ 2/Flux-tower/flux_data/REddyProc_input/for_gap_filling_partitioningBB2.txt", header = T)

# Delete first row that contains units
Input <- Input[-1, ]
Input <- data.frame(lapply(Input, function(x) as.numeric(as.character(x))))

Input$HH <- floor(Input$Hour)
Input$MM <- (Input$Hour-Input$HH)*60

# Create time stamp
Input$TIMESTAMP_END <- make_datetime(Input$Year, 1, Input$DoY, Input$HH, Input$MM)

# Define predictors
predictors <- c("FCH4", "Ustar","NEE","LE","H","Rg","Tair",'Tsoil5cm_1','Tsoil10cm_1','Tsoil30cm_1','Tsoil50cm_1','Tsoil5cm_2','Tsoil10cm_2','Tsoil30cm_2','Tsoil50cm_2', 'Tsoil5cm_3','Tsoil10cm_3','Tsoil30cm_3','Tsoil50cm_3',
                "rH","VPD","WTH","DoY") 

ML.df <- Input %>% select(predictors)

# Replace all -9999 with NA
ML.df[ML.df == -9999] <- NA

# Add sine and cosine functions
ML.df$s <- sin((ML.df$DoY-1)/365*2*pi)
ML.df$c <- cos((ML.df$DoY-1)/365*2*pi)

# period when FCH4 is not missing
wm_only <- ML.df[!is.na(ML.df$FCH4), ]

# 75% of data used for model tuning/validation
index <- createDataPartition(wm_only$FCH4, p=0.75, list=F) 
train_set <- wm_only[index,]
test_set <- wm_only[-index,]

############### Random forest run

#### option 1. random forest model with mtry tuning
#Add parallel processing for the fast processing if you want to
library(parallel)
library(doParallel)
#cluster <- makeCluster(6)
cluster <- parallel::makeCluster(10, setup_timeout = 0.5)
registerDoParallel(cluster)
RF_FCH4 <- train(FCH4 ~ ., data = train_set[,predictors],
 								 method = "rf",
 								 preProcess = c("medianImpute"),                #impute missing met data with median
 								 trControl=trainControl(method = "cv",   #three-fold cross-validation for model parameters 3 times
 								 											number = 3),
 								 na.action = na.pass,
 								 allowParallel=FALSE, # This requires parallel packages. Otherwise you can choose FALSE.
 								 ntree=400, # can generate more trees
 								 importance = TRUE)

RF_FCH4$bestTune
RF_FCH4$results

############### Results
# variable importance
plot(varImp(RF_FCH4, scale = FALSE), main="variable importance")

#generate FCH4_rf predictions for testset
test_set$FCH4_rf <- predict(RF_FCH4, test_set, na.action = na.pass)
regrRF <- lm(test_set$FCH4_rf ~ test_set$FCH4); 
print(summary(regrRF))
ggplot(test_set, aes(x=FCH4, y=FCH4_rf)) + geom_abline(slope = 1, intercept = 0)+
  geom_point() + geom_smooth(method = "lm") + ggtitle("testset")

# whole dataset
result <- data.frame(FCH4 = ML.df$FCH4) # you can add datetime column here if you want to.
result$FCH4_RF_model <- predict(RF_FCH4, ML.df, na.action = na.pass) # FCH4 RF model
result$FCH4_RF_filled <- ifelse(is.na(result$FCH4),result$FCH4_RF_model,result$FCH4) # gap-filled column (true value when it is, gap-filled value when missing)
result$FCH4_RF_residual <- ifelse(is.na(result$FCH4),NA,result$FCH4_RF_model - result$FCH4) # residual (model - obs). can be used for random uncertainty analysis

# time series
result$DateTime <- Input$TIMESTAMP_END

result %>% ggplot(aes(DateTime,FCH4)) + geom_point() + 
  theme_bw() + ylab(expression(paste("FCH4 (umol ", m^-2,s^-1,")")))
result %>% ggplot(aes(DateTime,FCH4_RF_filled)) + geom_point(color="red",alpha=0.5) +
  geom_point(aes(DateTime,FCH4),color="black")+
  theme_bw() + ylab(expression(paste("FCH4 (umol ", m^-2,s^-1,")")))

# whole data comparison
ggplot(result, aes(x = FCH4, y =FCH4_RF_model)) + geom_abline(slope = 1, intercept = 0)+
  geom_point() + geom_smooth(method = "lm") + ggtitle("whole dataset")
regrRF_whole <- lm(result$FCH4_RF_model ~ result$FCH4);
print(summary(regrRF_whole))
```

```{r Load L2 data, echo=FALSE, include=FALSE}
L2 <- read.csv(paste("/Users/marionnyberg/Google\ Drive/Micromet\ Lab/Projects/2019-Burns\ Bog\ 2/Flux-tower/flux_data/BB2_L2",".csv",sep = ""),sep=",",header=TRUE,dec=".")  

met <- read.csv('/Users/marionnyberg/Google\ Drive/Micromet\ Lab/Projects/2019-Burns\ Bog\ 2/Flux-tower/met_data/met_merged/met_corrected_gapfilledBB2.csv') 


# First, RF CH4 gap-filled data (figure out uncertainty for RF gap-filling)
L2$FCH4_gf_RF <- result$FCH4_RF_filled

# REddyProc data 
head(L2)
head(essential)

# Check to make sure files are of the same length and if TRUE, append to L2
if (nrow(L2) == nrow(essential)){
  # If TRUE, Combine
  L3 <- cbind(L2,essential)}

L3 <- merge(L3, met, by = "DATE") 


write_csv(L3,"/Users/marionnyberg/Google\ Drive/Micromet\ Lab/Projects/2019-Burns\ Bog\ 2/Flux-tower/flux_data/BB2_L3.csv")

# Check to make sure files are of the same length and if TRUE, append to L2
#if (nrow(L2) == nrow(essential)){
  # If TRUE, Combine
 # L3 <- cbind(L2,essential)
  #write_csv(L3,"/Users/marionnyberg/Google\ Drive/Micromet\ Lab/Projects/2019-Burns\ Bog\ #2/Flux-tower/flux_data/BB_L3.csv")
#}
```
