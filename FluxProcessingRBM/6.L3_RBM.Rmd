---
title: "6.L3"
author: "Sara Knox"
date: "04/20/2020"
output: html_document
---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())

library(plotly)
library(ggplot2)
library(ggpmisc) 

library(readxl)
library(tidyverse)
library(caret)
library(lubridate)
library(REddyProc)
library(tidyverse)
library(dplyr)
library(Rcpp)

siteID <- 'RBM'
Rdir <- "/Users/ziyi/Library/CloudStorage/GoogleDrive-ziyi.tzuyilu@gmail.com/.shortcut-targets-by-id/1txCh9lZ7VGCujXGvBaJCMVnuxT-65q4K/Micromet\ Lab/Projects/2022-RBM Richmond brackish marsh/Flux-tower"
setwd("/Users/ziyi/Library/CloudStorage/GoogleDrive-ziyi.tzuyilu@gmail.com/.shortcut-targets-by-id/1txCh9lZ7VGCujXGvBaJCMVnuxT-65q4K/Micromet Lab/Projects/2022-RBM Richmond brackish marsh/FluxProcessingRBM")

knitr::opts_knit$set(root.dir = Rdir)

```

```{r Load data, echo=FALSE, include=FALSE}
EddyData.F <- fLoadTXTIntoDataframe(paste(Rdir,"/Flux_data/REddyProc_input/for_gap_filling_partitioning",siteID,".txt",sep=''))
```

```{r Gap-fill and partition in REddyProc, echo=FALSE, include=FALSE}
# Converting DOY to integers
#EddyData.F$DoY <- floor(EddyData.F$DoY)


# Add time stamp in POSIX time format -------------------------------------
EddyDataWithPosix.F <- fConvertTimeToPosix(EddyData.F, 'YDH',Year.s = 'Year',Day.s = 'DoY',Hour.s = 'Hour')
##tmp <- fConvertTimeToPosix(EddyData.F, 'YDH',Year = 'Year',Day ='DoY',Hour = 'Hour')
##iStart = which(tmp$Hour == 0.5)[1] # first record on a new day
##EddyDataWithPosix.F <- tmp[iStart:nrow(tmp),]

##############
## [NEED TO BE MODIFIED]
## vvvvvv TEMPORARY DATAFRAME THAT DUPLICATES EDDYDATA TO MAKE 3-MONTH-LONG DATAFRAME. REMOVE AFTER AUGUST!!!!
##############
#TEMPEddyDataWithPosix.F <- rbind(EddyDataWithPosix.F,EddyDataWithPosix.F)
#rownames(TEMPEddyDataWithPosix.F) <- seq(1:dim(TEMPEddyDataWithPosix.F)[1])
#TEMPEddyDataWithPosix.F <- rbind(EddyDataWithPosix.F,EddyDataWithPosix.F,EddyDataWithPosix.F)
#last_idx <- length(EddyData.F$Year)

#for (i in 2:length(TEMPEddyDataWithPosix.F$DoY)) {
#  prev_hour <- TEMPEddyDataWithPosix.F$Hour[i-1]
#  prev_day <- TEMPEddyDataWithPosix.F$DoY[i-1]
#  prev_year <- TEMPEddyDataWithPosix.F$Year[i-1]
#  TEMPEddyDataWithPosix.F$DoY[i] <- prev_day
#  TEMPEddyDataWithPosix.F$Year[i] <- prev_year
#  # Hour
#  if (prev_hour != 23.5) {
#    TEMPEddyDataWithPosix.F$Hour[i] <- prev_hour+0.5
#  } else {
#    TEMPEddyDataWithPosix.F$Hour[i] <- 0.0
#  }
#  # Day
#  if (prev_day != 365 & prev_hour == 23.5) {
#    TEMPEddyDataWithPosix.F$DoY[i] <- prev_day + 1
#  } else if (prev_day == 365 & prev_hour == 23.5) {
#    TEMPEddyDataWithPosix.F$DoY[i] <- 1
#    TEMPEddyDataWithPosix.F$Year[i] <- prev_year+1
#  }
#}
#EddyDataWithPosix.F <- fConvertTimeToPosix(TEMPEddyDataWithPosix.F, 'YDH',Year.s = 'Year',Day.s = 'DoY',Hour.s = 'Hour')
##############
# ^^^^^^^ TEMPORARY DATAFRAME THAT DUPLICATES EDDYDATA TO MAKE 3-MONTH-LONG DATAFRAME. REMOVE AFTER AUGUST!!!!
##############





# Initalize R5 reference class sEddyProc for post-processing of eddy data with the variables needed for post-processing later -------------------------------------
EddyProc.C <- sEddyProc$new(siteID, EddyDataWithPosix.F,
														c("NEE","FCH4","LE","H","Ustar","Rg","Tair","RH","VPD",
														  "Ts_1_5cm","Ts_1_10cm","Ts_1_20cm","Ts_1_50cm",
														  "Ts_2_5cm","Ts_2_10cm","Ts_2_20cm","Ts_2_50cm",
														  'Cond','DO','WL','TW','pH','ORP'))
														  
														  #"Ts_2_5cm","Ts_2_10cm","Ts_2_20cm","Ts_2_50cm",
														  #'Cond','DO','WL','TW','pH','ORP'))

uStarTh <- EddyProc.C$sEstUstarThresholdDistribution(nSample = 100L, probs = c(0.05, 0.5, 0.95)) #added 14/12/2020 M.Nyberg
uStarTh %>%
  filter( aggregationMode == "year") %>%
  select( uStar, "5%", "50%", "95%") #added 14/12/2020 M.Nyberg

uStarThAnnual <-usGetAnnualSeasonUStarMap(uStarTh)[-2] #added 14/12/2020 M.Nyberg
uStarSuffixes <- colnames(uStarThAnnual)[-1] #added 14/12/2020 M.Nyberg
print(uStarThAnnual) #added 14/12/2020 M.Nyberg

EddyProc.C$sGetUstarScenarios() #added 22/03/2021 M.Nyberg
EddyProc.C$sMDSGapFillUStarScens('NEE', FillAll = TRUE) #added M.Nyberg 26/03/2021
EddyProc.C$sMDSGapFillUStarScens('FCH4', FillAll = TRUE) #added M.Nyberg 26/03/2021


grep("NEE_.*_f$",names(EddyProc.C$sExportResults()) #added M.Nyberg 26/03/2021
, value = TRUE)
grep("NEE_.*_fsd$",names(EddyProc.C$sExportResults()) #added M.Nyberg 26/03/2021
, value = TRUE)


# Use MDS for gap-filling NEE, H, LE, and FCH4 (but also use RF for FCH4) ----------------------------------
EddyProc.C$sMDSGapFill('NEE', FillAll.b = TRUE)
EddyProc.C$sMDSGapFill('LE', FillAll.b = TRUE)
EddyProc.C$sMDSGapFill('H', FillAll.b = TRUE)
EddyProc.C$sMDSGapFill('FCH4', FillAll.b = TRUE)



# Gap-filling met data for partitioning  ----------------------------------
EddyProc.C$sSetLocationInfo(Lat_deg.n = 49.1245, Long_deg.n = -123.1922, TimeZone_h.n = -8)
EddyProc.C$sMDSGapFill('Tair', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('VPD', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Rg', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Ts_1_5cm', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Ts_1_10cm', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Ts_1_20cm', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Ts_1_50cm', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Ts_2_5cm', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Ts_2_10cm', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Ts_2_20cm', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Ts_2_50cm', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('Cond', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('DO', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('WL', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('TW', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('pH', FillAll.b = FALSE)
EddyProc.C$sMDSGapFill('ORP', FillAll.b = FALSE)

# Apply nighttime gap-filling algorithm -----------------------------------
EddyProc.C$sMRFluxPartition()

resP <- lapply(uStarSuffixes, function(suffix){ #added M.Nyberg 26/03/2021
EddyProc.C$sMRFluxPartition(Suffix.s = suffix)
})

grep("GPP.*_f$|Reco", names(EddyProc.C$sExportResults()), value = TRUE) #added M.Nyberg 26/03/2021

#EddyProc.C$sApplyUStarScen(EddyProc.C$sMRFluxPartition )

EddyProc.C$sPlotFingerprintY('GPP_U50_f', Year = 2022)


# Apply daytime gap-filling algorithm -----------------------------------
EddyProc.C$sGLFluxPartition()

dayP <- lapply(uStarSuffixes, function(suffix){ #added M.Nyberg 26/03/2021
EddyProc.C$sGLFluxPartition(Suffix.s = suffix)
})

grep("GPP.*_f$|Reco|", names(EddyProc.C$sExportResults()), value = TRUE) #added M.Nyberg 26/03/2021


# Output results -----------------------------------
FilledEddyData.F <- EddyProc.C$sExportResults()
names(FilledEddyData.F)
```

```{r Gap-fill and partition in REddyProc_2, echo=FALSE, include=FALSE}
# Plot results -----------------------------------

# daily sums (from REddyProc) - CHECK UNITS!
setwd(paste(Rdir,'/flux_data',sep=''))
EddyProc.C$sPlotDailySums(Var.s = 'LE_f', Format.s = "png", unit.s = "MJ/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'H_f', Format.s = "png", unit.s = "MJ/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'NEE_f', Format.s = "png", unit.s = "gC/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'FCH4_f', Format.s = "png", unit.s = "gC/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'GPP_f', Format.s = "png", unit.s = "gC/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'Reco', Format.s = "png", unit.s = "gC/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'GPP_DT', Format.s = "png", unit.s = "gC/m2/day")
EddyProc.C$sPlotDailySums(Var.s = 'Reco_DT', Format.s = "png", unit.s = "gC/m2/day")
# Could create other plots to check the results
#....

```

```{r Save full REddyPro output, echo=FALSE, include=FALSE}
write_csv(FilledEddyData.F,paste(Rdir,'/flux_data/REddyProc_gapfilled_partition_fulloutput',siteID,'.csv',sep=''))
```

```{r Save only essential variables, echo=FALSE, include=FALSE}
essential_variables <- grep("NEE_f$|NEE_fsd$|GPP_f$|GPP_DT.*$|Reco|Reco_DT.*$|LE_f$|LE_fsd$|H_f$|H_fsd$|FCH4_f$|FCH4_fsd$|NEE_uStar_f|NEE_U05_f|NEE_U50_f|NEE_U95_f|NEE_uStar_fsd|NEE_U05_fsd|NEE_U50_fsd|NEE_U95_fsd",
														names(EddyProc.C$sExportResults()), value = TRUE)
essential_variables

# # Remove WTH
# essential_variables <- str_remove(essential_variables, "WTH_.*")

essential <- FilledEddyData.F[,which(names(FilledEddyData.F) %in% essential_variables)]
```

```{r gap-fill FCH4 using random forest from Kim et al. 2019, echo=FALSE, warning=FALSE}

# variable we need for FCH4 gap-filling
Input <- read.table(paste(Rdir,'/flux_data/REddyProc_input/for_gap_filling_partitioning',siteID,'.txt',sep=''), header = T)

# Delete first row that contains units
Input <- Input[-1, ]
Input <- data.frame(lapply(Input, function(x) as.numeric(as.character(x))))

Input$HH <- floor(Input$Hour)
Input$MM <- (Input$Hour-Input$HH)*60

# Create time stamp
Input$TIMESTAMP_END <- make_datetime(Input$Year, 1, Input$DoY, Input$HH, Input$MM)

# Define predictors
#predictors <- c("FCH4", "Ustar","NEE","LE","H","Rg","Tair","RH","VPD","DoY",
#                "Ts_1_5cm","Ts_1_10cm","Ts_1_20cm","Ts_1_50cm",
#                "Ts_2_5cm","Ts_2_10cm","Ts_2_20cm","Ts_2_50cm") 

# Added water measurements
predictors <- c("FCH4", "Ustar","NEE","LE","H","Rg","Tair","RH","VPD","DoY",
                "Ts_1_5cm","Ts_1_10cm","Ts_1_20cm","Ts_1_50cm",
                "Cond","WL","TW",
                "Ts_2_5cm","Ts_2_10cm","Ts_2_20cm","Ts_2_50cm")
#                ,"Cond","DO","WL","TW","pH","ORP") 

ML.df <- Input %>% select(predictors)

# Replace all -9999 with NA
ML.df[ML.df == -9999] <- NA

# Add sine and cosine functions
ML.df$s <- sin((ML.df$DoY-1)/365*2*pi)
ML.df$c <- cos((ML.df$DoY-1)/365*2*pi)

# period when FCH4 is not missing
wm_only <- ML.df[!is.na(ML.df$FCH4), ]

############### Random forest run 20x ###############

#Add parallel processing for the fast processing if you want to
library(parallel)
library(doParallel)
library(caret)
library(data.table)

combined_result <- list()

for(i in 1:20){
  
  start_time <- Sys.time()
  # setting seed
  set.seed(i)
  train_rows <- sample(1:nrow(wm_only), 0.75*nrow(wm_only))
  # select the training set
  train_set <- wm_only %>% slice(train_rows)
  # select the validation set
  test_set <- anti_join(wm_only, train_set)
  #### option 1. random forest model with mtry tuning
  #cluster <- makeCluster(6)
  cluster <- parallel::makeCluster(10, setup_timeout = 0.5)
  registerDoParallel(cluster)
  RF_FCH4 <- train(FCH4 ~ ., data = train_set[,predictors],
   								 method = "rf",
   								 preProcess = c("medianImpute"),                #impute missing met data with median
   								 trControl=trainControl(method = "cv",   #three-fold cross-validation for model parameters 3 times
   								 											number = 3),
   								 na.action = na.pass,
   								 # allowParallel=FALSE, # This requires parallel packages. Otherwise you can choose FALSE.
   								 ntree=400, # can generate more trees
   								 importance = TRUE)
  
  RF_FCH4$bestTune
  RF_FCH4$results
  
  ############### Results
  # Variable importance
  print(plot(varImp(RF_FCH4, scale = FALSE), 
             main=paste("[Test - ",i,"] variable importance",sep=""))) 
  
  
  
  # Generate FCH4_rf predictions for testset
  test_set$FCH4_rf <- predict(RF_FCH4, test_set, na.action = na.pass)
  regrRF <- lm(test_set$FCH4_rf ~ test_set$FCH4); 
  print("RF Summary of test data:")
  print(summary(regrRF))
  
  my.formula <- y ~ x
  print(ggplot(test_set, aes(x=FCH4, y=FCH4_rf)) + 
    geom_abline(slope = 1, intercept = 0, aes(colour="identity line"))+
    geom_point() + geom_smooth(method = "lm", formula = my.formula, aes(colour="linear model")) + 
    scale_color_manual(values = c("identity line" = "black", "linear model" = "blue"))+
    stat_poly_eq(formula = my.formula, aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),parse = TRUE) +
    ggtitle(paste("[Test - ",i,"] Test result",sep=""))) 
    

    
  # whole dataset
  result <- data.frame(FCH4 = ML.df$FCH4) # you can add datetime column here if you want to.
  result$FCH4_RF_model <- predict(RF_FCH4, ML.df, na.action = na.pass) # FCH4 RF model
  result$FCH4_RF_filled <- ifelse(is.na(result$FCH4),result$FCH4_RF_model,result$FCH4) 
  # gap-filled column (true value when it is, gap-filled value when missing)
  result$FCH4_RF_residual <- ifelse(is.na(result$FCH4),NA,result$FCH4_RF_model - result$FCH4) 
  # residual (model - obs). can be used for random uncertainty analysis
  
  # time series
  result$DateTime <- Input$TIMESTAMP_END
  
  #result %>% ggplot(aes(DateTime,FCH4)) + geom_point() + 
  #  theme_bw() + ylab(expression(paste("FCH4 (umol ", m^-2,s^-1,")"))) %>% 
  #  print()

  #  result %>% ggplot(aes(DateTime,FCH4_RF_filled)) + 
  #  geom_point(color="red",alpha=0.5) +
  #  geom_point(aes(DateTime,FCH4),color="black")+
  #  theme_bw() + ylab(expression(paste("FCH4 (umol ", m^-2,s^-1,")"))) %>% 
  #  print()
    
  print(result %>% ggplot(aes(DateTime,FCH4)) + geom_point() + 
    theme_bw() + ylab(expression(paste("FCH4 (umol ", m^-2,s^-1,")",sep=""))) +
    ggtitle(paste("FCH4 original time series",sep="")))
  
  print(result %>% ggplot(aes(DateTime,FCH4_RF_filled)) + 
    geom_point(aes(color="FCH4_RF_Filled"),alpha=0.5) +
    geom_point(aes(DateTime,FCH4,color="FCH4"))+
    scale_color_manual(values = c("FCH4_RF_Filled" = "red", "FCH4" = "black"))+
    theme_bw() + ylab(expression(paste("FCH4 (umol ", m^-2,s^-1,")",sep=""))) +
    ggtitle(paste("FCH4 gap-filled time series",sep="")))

  
  # whole data comparison
  print(ggplot(result, aes(x = FCH4, y =FCH4_RF_model)) + 
          geom_abline(slope = 1, intercept = 0, aes(colour="identity line"))+
          geom_point() + geom_smooth(method = "lm", formula = my.formula, aes(colour="linear model")) + 
          stat_poly_eq(formula = my.formula, aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),parse = TRUE)+
          ggtitle(paste("[Test - ",i,"] whole dataset",sep=""))+
    scale_color_manual(values = c("identity line" = "black", "linear model" = "blue")))
  
  regrRF_whole <- lm(result$FCH4_RF_model ~ result$FCH4);
  print("RF Summary of whole data:")
  print(summary(regrRF_whole))
  
  
  result$iteration <- i 
  combined_result[[i]] <- result
  end_time <- Sys.time()
  end_time - start_time
}

rf_result_df <- data.table::rbindlist(combined_result)
write_csv(rf_result_df,paste(Rdir,'/flux_data/',siteID,'_rf_result.csv',sep=''))

```



```{r Load L2 data, echo=FALSE, include=FALSE}
L2 <- read.csv(paste(Rdir,'/flux_data/',siteID,'_L2.csv',sep = ''),header=TRUE,dec=".")
met <- read.csv(paste(Rdir,'/met_data/Gapfilled_biomet.csv',sep = ''))

#L2 <- L2[iStart:nrow(tmp),]
#met <- met[iStart:nrow(tmp),]

# Calculate salinity from conductivity
met$Salinity <- ((met$COND_1_1_1/1000)^1.0878)*0.4665

# Convert Air Pressure from Pa -> kPa
met$PA_1_1_1 <- met$PA_1_1_1/1000

names(met)[names(met) == "DOY"] <- "doy_int"
# Exclude duplicate variables 
met <- select(met,-c(date,time,Year_local,jday_local,month_local,hour_local,time_local,DOY_local,min_local))

# Reorder columns
  # since the order changes from to time, use variable names to reorder.
  #met <- met[,c(1,2,58,59,65,3,4,66,5:57)]
met <- select(met,c(ALB_1_1_1,COND_1_1_1, Salinity, DO_1_1_1:PA_1_1_1, pH_1_1_1,
                     PPFD_2_1_1,PPFDR_1_1_1:PPFD_2_1_1,
                     PPFDD_1_1_1,PRI_1_1_1:nm570out_1_1_1,
                     year,doy_int,DATE,hour,NR,G,AE,es,VPD,obs1))





# First, RF CH4 gap-filled data (figure out uncertainty for RF gap-filling)
#L2$FCH4_gf_RF <- result$FCH4_RF_filled[iStart:nrow(tmp)]
L2$FCH4_gf_RF <- result$FCH4_RF_filled

# REddyProc data 
head(L2)
head(essential)

################################################
# TEMP for Data no longer than three month
essential <- essential[1:dim(L2)[1],]
################################################


# Check to make sure files are of the same length and if TRUE, append to L2
if (nrow(L2) == nrow(essential)){
  # If TRUE, Combine L2 and essential-flux
  L3 <- cbind(L2,essential)
}


# Merge flux and met data
L3 <- merge(L3, met, by = "DATE") 

write_csv(L3,paste(Rdir,'/Flux_data/',siteID,'_L3.csv',sep=''))

```
