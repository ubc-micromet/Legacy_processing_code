---
title: "5.L2_filtering"
author: "Sara Knox"
date: "11/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())

library(plotly)
library(readxl)
library(REddyProc)
library(tidyverse)
library(dplyr)
library(lubridate)
library(gtools)

# set wd
getwd()
dir <- "/Users/darianng/Google\ Drive/My\ Drive/Micromet\ Lab/Projects/2021-Young/Flux-tower"
knitr::opts_knit$set(root.dir = dir)
```

```{r Load non-filtered data, echo=FALSE, include=FALSE}
input<-read.csv(paste('./flux_data/Young_L1.csv',sep=''))
input$DATE<-as.POSIXct(input$DATE,format="%Y-%m-%d %H:%M:%S", tz = "UTC")

# Define new data frame
Data_QAQC<-input
```

```{r Define L2 filters, echo=FALSE, include=FALSE}
pitch_max <- 7 #[deg]
pitch_min <- -7 #[deg]
# WD -> ADD LATER!
qc_flag <- 1 #[#]
w.ts_cov_max <- 0.5 #[m+1K+1s-1]
ts_var_max <- 3 #[K+2]
mean_value_RSSI_LI.7200_min <- 50 #[#] % CONFIRM
h2o_flux_min <- -2 #[mmol+1s-1m-2]
h2o_flux_max <- 15 #[mmol+1s-1m-2]
h2o_var_max <- 9000
h2o_mean_max <- 2000 #[mmol/m3]
co2_mean_min <- 12 #[mmol/m3]
co2_var_max <- 0.2
co2_flux_max <- 50 #[µmol+1s-1m-2]
co2_flux_min <- -60 #[µmol+1s-1m-2]
rssi_77_mean_min <- 20; #[#] 
ch4_mean_min <- 1.7 # [ppm]
ch4_var_max <- 0.0005
ch4_flux_min <- -0.2 #[µmol+1s-1m-2]
ch4_flux_max <- 0.7 #[µmol+1s-1m-2]
ustar_max <- 1.2
wind_max <- 330 #degrees - added 14/12/20 - M.Nyberg
wind_min <- 30 #degrees - added 14/12/20 - M.Nyberg
L_max <- 10000 # [m] - added 13/08/21 - D. Ng
L_min <- -10000 # [m] - added 13/08/21 - D. Ng


# Plot filtering variable of interest to check values
plot_ly(data = Data_QAQC, x = ~DATE, y = ~co2_var, name = 'pitch', type = 'scatter', mode = 'line') %>%
 layout(yaxis = list(range = c(-1, 1))) %>% 
  toWebGL()
```

```{r Create flags (with the exception of the ustar flag), echo=FALSE, include=FALSE}
Data_QAQC$badrot <- ifelse(input$pitch > pitch_max | input$pitch < pitch_min,1,0)

Data_QAQC$badt <- ifelse(abs(input$w.ts_cov) > w.ts_cov_max | input$ts_var > ts_var_max | input$qc_H > qc_flag,1,0)

Data_QAQC$badq <- ifelse(input$h2o_flux < h2o_flux_min | input$h2o_flux > h2o_flux_max | input$h2o_var > h2o_var_max | input$h2o_mean > h2o_mean_max | input$mean_value_RSSI_LI.7200 < mean_value_RSSI_LI.7200_min | input$qc_LE > qc_flag,1,0)

Data_QAQC$badc <- ifelse(input$co2_flux < co2_flux_min | input$co2_flux > co2_flux_max | input$co2_var > co2_var_max | input$co2_mean < co2_mean_min | input$mean_value_RSSI_LI.7200 < mean_value_RSSI_LI.7200_min | input$qc_co2_flux > qc_flag,1,0)

Data_QAQC$badm <- ifelse(input$ch4_flux < ch4_flux_min | input$ch4_flux > ch4_flux_max | input$ch4_var > ch4_var_max | input$ch4_mean < ch4_mean_min | input$rssi_77_mean < rssi_77_mean_min | input$qc_ch4_flux > qc_flag,1,0)

Data_QAQC$badwind <- ifelse(input$wind_dir > wind_max | input$wind_dir < wind_min,1,0) #added 14/12/20 - M.Nyberg

Data_QAQC$badL <- ifelse(input$L > L_max | input$L < L_min,1,0) # Added 13/08/21 - D.Ng
```

```{r Filter relevant CO2 variables to run ustar filtering next, echo=FALSE, warning=FALSE}
Data_QAQC$co2_flux[Data_QAQC$badc == 1] <- NA

# Plot unfiltered & filtered CO2 data
plot_ly(data = input, x = ~DATE, y = ~co2_flux, name = 'original', type = 'scatter', mode = 'markers',marker = list(size = 3)) %>%
  add_trace(data = Data_QAQC, x = ~DATE, y = ~co2_flux, name = 'filtered', mode = 'markers') %>% 
  toWebGL()

# Plot only unfiltered data
plot_ly(data = Data_QAQC, x = ~DATE, y = ~co2_flux, name = 'original', type = 'scatter', mode = 'markers',marker = list(size = 3)) %>% 
  toWebGL()
```

```{r Prepare data for ustar filtering using REddyProc, echo=FALSE, include=FALSE}

# Loading biomet data

# 07/07/2021 - Darian Ng
# For integrated biomet outputs from Eddypro (i.e. licor): Instead of reading met_merged biomet csv, load each biomet file from EP_outputs and compile them into a dataframe. 
# POSSIBLE ISSUE: list.files(path=path,pattern="biomet") sometimes won't recognize each biomet file as a unique list element.
# Original: met <- read.csv(paste('./met_data/met_merged/','met_corrected_gapfilledBB2.csv',sep=""),sep=",",header=TRUE,dec=".")
met.files <- list.files(path = paste(dir,"/EP_outputs",sep=""), pattern = "biomet")
met <- data.frame()

# Compiling into dataframe
for(i in 1:length(met.files)) {
	# Get header names
	names_temp <- names(read.csv(paste(dir,"/EP_outputs/",met.files[i],sep=""),skip=0,sep=",",header=TRUE,dec="."))
	
	# Load data & apply header names
	temp <- read.csv(paste(dir,"/EP_outputs/",met.files[i],sep=""),skip=2,header=FALSE) #skip=3 means skip the first 3 rows of the file
	names(temp) <- names_temp
	
	# Append to file
	met <- smartbind(met,temp, fill = "NA")
}

# Formatting met date as yyyy-mm-dd hh:mm:ss to include time and adding "Year" and "hour" columns
for(i in 1:length(met$date)) {
  time <- met$time[i]
  met$date[i] <- paste(met$date[i],time)
  
  Yr <- as.numeric(substr(met$date[i],start=1,stop=4))
  Hr <- as.numeric(substr(met$time[i],start=1,stop=2))
  
  Min <- substr(met$time[i],start=4,stop=5)
  if (Min == "30") {
    Hr <- Hr+0.5
  } 
  
  met$year[i] <- Yr
  met$hour[i] <- Hr
  
}

# Creating columns for new & renamed variables: net radiation, saturated vapour pressure (es), vpd. --> Missing Soil Heat Flux, so can't derive soil heat flux (G), & available energy (ae),
met$NR <- met$RN_1_1_1

# Converting air and soil temp to Celsius
met$TA_1_1_1 <- met$TA_1_1_1 - 273.15
met$TS_1_1_1 <- met$TS_1_1_1 - 273.15
met$TS_2_1_1 <- met$TS_2_1_1 - 273.15
met$TS_3_1_1 <- met$TS_3_1_1 - 273.15

met$es <- 0.611*exp(17.502*met$TA_1_1_1/(met$TA_1_1_1+240.97))
met$VPD <- met$es*(1-(met$RH_1_1_1/100))


met$Timestamp<-as.POSIXct(paste(met$date, met$time), format="%Y-%m-%d %H:%M", tz = "Etc/GMT+8")

###
# GAPFILLING: Checking for gaps in half-hourly data, then filling with NA in a new dataframe.
###

# Ordering data by date/time
data.ordered<-met[order(met$Timestamp, decreasing = FALSE ),]

data.ordered[1,1:5]
data.ordered[nrow(data.ordered),1:5]

# Generating new dataframe and gapfilling with NA

ts<-data.ordered

#to estimate necessary parameters to generate the new empty dataframe with complete rows 
beginning<-as.numeric(ts$Timestamp[1])      # Finding number representing the first data of our time series
as.POSIXct(beginning,origin="1970-01-01 00:00:00",tz="Etc/GMT+8") # to confirm that the beginning is the right one
ts$Timestamp[1]

Ystart<-as.integer(as.character(ts[1,ncol(ts)], "%Y")) # Starting year
Yend<-as.integer(as.character(ts[nrow(ts),ncol(ts)], "%Y")) # End  year
Dstart<-as.POSIXlt(ts[1,ncol(ts)])$yday # Starting date
Dend<-as.POSIXlt(ts[nrow(ts),ncol(ts)])$yday+1 # End date

Ndays <- as.numeric((difftime(ts$Timestamp[nrow(ts)],ts$Timestamp[1], "Etc/GMT+8",
                              units = c("days"))), units="days")

Tsteps<-beginning+seq(from=0,to=((Ndays)*(60*60*24)),by=(30*60)) # 30 minute steps in seconds from the beginning date to Ndays +1 (to ensure all measured data are included in the new file)
DATE<-as.POSIXct(Tsteps,origin="1970-01-01 00:00:00",tz="Etc/GMT+8") # Turning steps back into dates

# CHECK start and end times between the two files are equal.
DATE[1] == ts$Timestamp[1]
DATE[length(DATE)] == ts$Timestamp[length(ts$Timestamp)]

#GENERATING A NEW DATA FRAME WITH CONTINUOUS TIME STEPS and data from THE ORIGINAL ONE
cont.DS<-as.data.frame(DATE)
cont.DS[,c("DATE",names(ts)[1:(length(names(ts)))-1])]<-NA
cont.DS$DATE<-DATE

#FILLING THE NEW DATAFRAME WITH DATA FROM THE ORIGINAL DATA FRAME 
for(i in 2:ncol(cont.DS)){  
  cont.DS[,i]<-ts[pmatch(cont.DS$DATE,ts$Timestamp),i-1]  
  #pmatch look for the observation rows when time columns of both (old and new) dataframes match
} 

# Adding local time

date_loca <- ymd_hms(cont.DS$DATE, tz="America/Vancouver")
date_local<-as.POSIXlt(date_loca,tz="America/Vancouver")

for (i in 1:nrow(cont.DS)){
  cont.DS$Year_local[i]<-as.integer(as.character(date_local[i],"%Y"))
  cont.DS$jday_local[i]<-as.POSIXlt(date_local[i])$yday+1
  cont.DS$month_local[i]<-as.numeric(format(date_local[i],"%m"))
  cont.DS$hour_local[i]<-as.integer(as.character(date_local[i],"%H"))
  cont.DS$min_local[i]<-sprintf("%02s",as.integer(as.character(date_local[i],"%M")))  #sprintf function converts 0 in 00 to be pasted with hour to generate local time
  cont.DS$time_local[i]<-paste(cont.DS$hour_local[i],cont.DS$min_local[i],sep=":")
  day_portion<-ifelse(cont.DS$min_local[i]=="00",as.numeric(cont.DS$hour_local[i]),as.numeric(cont.DS$hour_local[i])+0.5)
  cont.DS$DOY_local[i]<-cont.DS$jday_local[i]+(day_portion*2*0.02)
}

# Replacing -9999 by NA
cont.DS[cont.DS == -9999] <- NA

met <- cont.DS

#Match met and flux time series
met$date <- as.POSIXct(met$date, Origin = "1970-01-01 00:00:00", tz = "UTC")

# Plot met data if needed
# Eddypro biomet variable reference list: https://www.licor.com/env/support/EddyPro/topics/biomet-data-format.html, https://www.licor.com/env/support/Biomet-System/topics/viewing-logged-data.html
plot_ly(data = met, x = ~date, y = ~TA_1_1_1, type = 'scatter', mode = 'lines') %>% 
  toWebGL()

Data_QAQC$DATE[1]
met$date[1]

Data_QAQC$obs<-c(1:nrow(Data_QAQC))
met$obs1 <- c(1:nrow(met)) #Testing because 'obs' column doesn't start at 1 for some reason

start_date<-Data_QAQC$DATE[1]

if (Data_QAQC$DATE[nrow(Data_QAQC)]>met[nrow(met),1]) { end_date<-met[nrow(met),1] 
}else{
  end_date<-Data_QAQC$DATE[nrow(Data_QAQC)]
}

start_date  #start of matching period
end_date    #end of matching period

F_start<-Data_QAQC[Data_QAQC$DATE==start_date,match('obs',names(Data_QAQC))] 
F_end<-Data_QAQC[Data_QAQC$DATE==end_date,match('obs',names(Data_QAQC))]

# M_start<-met[met$date==start_date,match('obs1',names(met))] #TEST
# M_end<-met[met$date==end_date,match('obs1',names(met))] #TEST

start_bool <- met$date==start_date
end_bool <- met$date == end_date

M_start<-met[which(start_bool==TRUE),match('obs1',names(met))] #TEST
M_end<-met[which(end_bool==TRUE),match('obs1',names(met))] #TEST

M_end-M_start==F_end-F_start   #If everything goes well this should be TRUE 

# # Create output file to use in REddyProc for ustar filtering
# output <- cbind(met[M_start:M_end,match(c('year','jday','hour_dec','AIR_TEMP_2M','SHORTWAVE_IN'),names(met))], Data_QAQC[F_start:F_end,match(c('co2_flux','u.'),names(Data_QAQC))])
output <- cbind(met[M_start:M_end,match(c('year','DOY','hour','TA_1_1_1','SWIN_1_1_1'),names(met))], Data_QAQC[F_start:F_end,match(c('co2_flux','u.'),names(Data_QAQC))])

# rounding DOY down
output$DOY <- floor(output$DOY)

#01/07/2020 - for some reason I can't get the above to work 
#output <- cbind(met[2461:8174,match(c('year','jday','hour_dec','AIR_TEMP_2M','SHORTWAVE_IN'),names(met))], #Data_QAQC[F_start:F_end,match(c('co2_flux','u.'),names(Data_QAQC))])


# Reorder & rename columns
output <- output[c("year","DOY", "hour","co2_flux","SWIN_1_1_1","TA_1_1_1","u.")]
names_output<-c('Year','DoY','Hour','NEE','Rg','Tair','Ustar')
names(output)<-names_output
  
#Adding the units row
UNITS<-list('-','-','-','umol_m-2_s-1','Wm-2','degC','ms-1')

output <- rbind(UNITS,output)

#Transforming missing values in -9999:
output[is.na(output)]<--9999



#Saving the file:
write.table(output, file = paste('./flux_data/REddyProc_input/for_ustar_filtering','.txt',sep=''),row.names=FALSE,sep='\t') 
```

```{r Ustar filtering in REddyProc, echo=FALSE, warning=FALSE, include=FALSE}
# Load data
EddyData.F <- fLoadTXTIntoDataframe("./flux_data/REddyProc_input/for_ustar_filtering.txt")

#Gapfill year and hour NA's
na_idx = which(is.na(EddyData.F$Hour))

for (idx in na_idx){
  previous_hour = EddyData.F$Hour[idx-1]
  previous_day = EddyData.F$DoY[idx-1]
  previous_year = EddyData.F$Year[idx-1]
  # Stepping into missing hour for EddyData.F and met
  if (previous_hour != 23.5) {
    EddyData.F$Hour[idx] <- previous_hour + 0.5
    met$hour[idx] <- met$hour[idx-1] +0.5
  } else{
    EddyData.F$Hour[idx] <- 0
    met$hour[idx] <- 0
  }
  # Stepping into missing day
  if (previous_hour == 23.5 & previous_day == 365) {
    EddyData.F$DoY[idx] <- 1
    met$DOY[idx] <- 1
  } else if (previous_hour == 23.5 & previous_day != 365) {
    EddyData.F$DoY[idx] <- previous_day + 1
    met$DOY[idx] <- met$DOY[idx-1] + 0.0208
  } else if (previous_hour < 23.5) {
    EddyData.F$DoY[idx] <- previous_day
    met$DOY[idx] <- met$DOY[idx-1] + 0.0208
  }
  # Stepping into missing year
  if (previous_hour == 23.5 & previous_day == 365) {
    EddyData.F$Year[idx] <- previous_year + 1
    met$year[idx] <- met$year[idx-1] + 1
  } else {
    EddyData.F$Year[idx] <- previous_year
    met$year[idx] <- met$year[idx-1]
  }
}

#######
# vvvvvvvvvv TEMPORARY !!!!!!!!! REMOVE AFTER JULY 26 WHEN THERE'S 3 MONTH'S DATA!!!!!
######

# Spoofing dataframe to fill 3 months of data needed by sEddyProc. Adding 3 months
last_idx <- length(EddyData.F$Year)
needed_length <- 3*48*31
extra_length <- needed_length-last_idx

extra_rows<-as.data.frame(c(1:extra_length))
extra_rows[,c(names(EddyData.F)[1:(length(names(EddyData.F)))])]<-NA

# EddyData.F <- rbind(EddyData.F,extra_rows[1:extra_length,2:8])
EddyData.F <- rbind(EddyData.F,EddyData.F,EddyData.F)

# for (idx in last_idx:needed_length) {
for (idx in last_idx:length(EddyData.F$Year)) {
  previous_hour = EddyData.F$Hour[idx-1]
  previous_day = EddyData.F$DoY[idx-1]
  previous_year = EddyData.F$Year[idx-1]
  # Stepping into missing hour
  if (previous_hour != 23.5) {
    EddyData.F$Hour[idx] <- previous_hour + 0.5
  } else{
    EddyData.F$Hour[idx] <- 0
  }
  # Stepping into missing day
  if (previous_hour == 23.5 & previous_day == 365) {
    EddyData.F$DoY[idx] <- 1
  } else if (previous_hour == 23.5 & previous_day != 365) {
    EddyData.F$DoY[idx] <- previous_day + 1
  } else if (previous_hour < 23.5) {
    EddyData.F$DoY[idx] <- previous_day
  }
  # Stepping into missing year
  if (previous_hour == 23.5 & previous_day == 365) {
    EddyData.F$Year[idx] <- previous_year + 1
  } else {
    EddyData.F$Year[idx] <- previous_year
  }
}
#######
# ^^^^^^^^^ TEMPORARY !!!!!!!!! REMOVE AFTER JULY 26 WHEN THERE'S 3 MONTH'S DATA!!!!!
######


# Add time stamp in POSIX time format
EddyDataWithPosix.F <- fConvertTimeToPosix(EddyData.F, 'YDH',Year.s = 'Year',Day.s = 'DoY',Hour.s = 'Hour')



EddyProc.C <- sEddyProc$new('YOUNG-CE', EddyDataWithPosix.F,
                            c("NEE","Rg","Tair","Ustar"))



# Single ustar threshold estimate
uStarTh <- EddyProc.C$sEstUstarThreshold()$uStarTh

# ustar threshold decision: separate for each individual year
threshold <- uStarTh %>% filter(aggregationMode == "year")
threshold <- threshold[, c(2,4)]
years <- threshold[, 1]
nyears <- length(years)

Data_QAQC$ustar_thr <- rep(0, nrow(Data_QAQC))
for (i in 1:nyears){
  Data_QAQC$ustar_thr[year(Data_QAQC$DATE) == years[i]] <- threshold[i, 2]
}
```

```{r Plot ustar threshold, echo=FALSE}
plot_ly(data = Data_QAQC, x = ~DATE, y = ~ustar_thr, type = 'scatter', mode = 'lines') %>% 
  toWebGL()
```

```{r Create bad ustar flag, echo=FALSE, warning=FALSE}
Data_QAQC$badustar <- ifelse(abs(input$u.) < Data_QAQC$ustar_thr | input$u. > ustar_max,1,0)

plot_ly(data = Data_QAQC, x = ~DATE, y = ~u., name = 'original', type = 'scatter', mode = 'lines') %>%
  add_trace(data = Data_QAQC, x = ~DATE[badustar == 1], y = ~u.[badustar == 1], name = 'removed', mode = 'markers') %>% 
  toWebGL() 
```

```{r Now filter everybody - ADD WIND DIRECTION FILTER! & STORAGE TERMS, echo=FALSE, warning=FALSE}
Data_QAQC$badflux = Data_QAQC$badustar | Data_QAQC$badt | Data_QAQC$badrot
Data_QAQC$L[Data_QAQC$badflux == 1]  <- NA
Data_QAQC$X.z.d..L[Data_QAQC$badflux == 1]  <- NA
Data_QAQC$co2_flux[Data_QAQC$badflux == 1]  <- NA
Data_QAQC$ch4_flux[Data_QAQC$badflux == 1]  <- NA
Data_QAQC$h2o_flux[Data_QAQC$badflux == 1]  <- NA
Data_QAQC$ET[Data_QAQC$badflux == 1]  <- NA
Data_QAQC$LE[Data_QAQC$badflux == 1]  <- NA
Data_QAQC$H[Data_QAQC$badflux == 1]  <- NA

# Filter momentum fluxes for bad rotation angle only
Data_QAQC$Tau[Data_QAQC$badrot] <- NA

# Bad water fluxes
Data_QAQC$h2o_flux[Data_QAQC$badq == 1] <- NA
Data_QAQC$LE[Data_QAQC$badq == 1] <- NA
Data_QAQC$ET[Data_QAQC$badq == 1] <- NA

# Bad CO2 fluxes
Data_QAQC$co2_flux[Data_QAQC$badc == 1] <- NA

# Bad CH4 fluxes
Data_QAQC$ch4_flux[Data_QAQC$badm == 1]  <- NA

# Bad wind direction - added 14/12/20 M.Nyberg
Data_QAQC$wind_dir[Data_QAQC$badwind == 1]  <- NA

# Bad Monin-Obukhov Length - added 13/08/21 D.Ng
Data_QAQC$L[Data_QAQC$badL == 1]  <- NA

```

```{r Plot L2 fluxes, echo=FALSE, warning=FALSE}
# Turbulence

# Add WD eventually

# ustar
plot_ly(data = input, x = ~DATE, y = ~u., name = 'original', type = 'scatter', mode = 'line') %>%
  add_trace(data = Data_QAQC, x = ~DATE[badustar == 1], y = ~u.[badustar == 1], name = 'filtered', mode = 'markers') %>% 
  toWebGL()

# z/L
plot_ly(data = input, x = ~DATE, y = ~X.z.d..L, name = 'original', type = 'scatter', mode = 'line') %>%
  add_trace(data = Data_QAQC, x = ~DATE, y = ~X.z.d..L, name = 'retained', mode = 'line') %>%
  layout(yaxis = list(range = c(-20, 20))) %>% 
  toWebGL()

# Fluxes
plot_ly(data = input, x = ~DATE, y = ~H, name = 'original', type = 'scatter', mode = 'markers', marker = list(size = 3)) %>%
  add_trace(data = Data_QAQC, x = ~DATE, y = ~H, name = 'retained', mode = 'markers') %>% 
  toWebGL()

plot_ly(data = input, x = ~DATE, y = ~LE, name = 'original', type = 'scatter', mode = 'markers', marker = list(size = 3)) %>%
  add_trace(data = Data_QAQC, x = ~DATE, y = ~LE, name = 'retained', mode = 'markers') %>% 
  toWebGL()

plot_ly(data = input, x = ~DATE, y = ~co2_flux, name = 'original', type = 'scatter', mode = 'markers', marker = list(size = 3)) %>%
  add_trace(data = Data_QAQC, x = ~DATE, y = ~co2_flux, name = 'retained', mode = 'markers') %>%
 layout(yaxis = list(range = c(-40, 30))) %>% 
  toWebGL()

plot_ly(data = input, x = ~DATE, y = ~ch4_flux*1000, name = 'original', type = 'scatter', mode = 'markers', marker = list(size = 3)) %>%
  add_trace(data = Data_QAQC, x = ~DATE, y = ~ch4_flux*1000, name = 'retained', mode = 'markers') %>%
 layout(yaxis = list(range = c(-300, 800))) %>% 
  toWebGL()

# Bad rotatoion angle
plot_ly(data = input, x = ~DATE, y = ~pitch, name = 'original', type = 'scatter', mode = 'line') %>%
  add_trace(data = Data_QAQC, x = ~DATE[badrot == 1], y = ~pitch[badrot == 1], name = 'filtered', mode = 'markers') %>% 
  toWebGL()

# Wind direction - added 14/12/2020 - M.Nyberg - not sure if this has worked but there are NAs in the Data_QAQC file
plot_ly(data = input, x = ~DATE, y = ~wind_dir, name = 'original', type = 'scatter', mode = 'line') %>%
  add_trace(data = Data_QAQC, x = ~DATE[badwind == 1], y = ~wind_dir[badwind == 1], name = 'filtered', mode = 'markers') %>% 
  toWebGL()

# Variances
plot_ly(data = input, x = ~DATE, y = ~ts_var, name = 'original', type = 'scatter', mode = 'line') %>%
  add_trace(data = Data_QAQC, x = ~DATE[ts_var > ts_var_max], y = ~ts_var[ts_var > ts_var_max], name = 'filtered', mode = 'markers') %>% 
  toWebGL()

plot_ly(data = input, x = ~DATE, y = ~h2o_var, name = 'original', type = 'scatter', mode = 'line') %>%
  add_trace(data = Data_QAQC, x = ~DATE[h2o_var > h2o_var_max], y = ~h2o_var[h2o_var > h2o_var_max], name = 'filtered', mode = 'markers') %>% 
  toWebGL()

plot_ly(data = input, x = ~DATE, y = ~co2_var, name = 'original', type = 'scatter', mode = 'line') %>%
  add_trace(data = Data_QAQC, x = ~DATE[co2_var > co2_var_max], y = ~co2_var[co2_var > co2_var_max], name = 'filtered', mode = 'markers') %>%
  layout(yaxis = list(range = c(-100,10000))) %>% 
  toWebGL()

plot_ly(data = input, x = ~DATE, y = ~ch4_var, name = 'original', type = 'scatter', mode = 'line') %>%
  add_trace(data = Data_QAQC, x = ~DATE[ch4_var > ch4_var_max], y = ~ch4_var[ch4_var > ch4_var_max], name = 'filtered', mode = 'markers') %>%
  layout(yaxis = list(range = c(-1,1))) %>% 
  toWebGL()
```
```{r Plot energy balance closure, echo=FALSE, warning=FALSE}
# Ebal_denominator <- met$NR[M_start:M_end]-met$G[M_start:M_end]
# 
# Ebal_numerator <- Data_QAQC$H+Data_QAQC$LE
# 
# plot(x = Ebal_denominator, y = Ebal_numerator, xlab="Rn-G",ylab="LE+H")
# 
# # calculate EB using slope to fit
# a<-round(coef(lm(Ebal_numerator~Ebal_denominator))[2],digits=2) #coef(lm(y~x))[2] is the slope of the regression
# b<-round(coef(lm(Ebal_numerator~Ebal_denominator))[1],digits=2)   
# r2<-round(summary(lm(Ebal_numerator~Ebal_denominator))$ r.squared,digits=2)
# 
# lm_eq<-paste0("y=",a,"x",ifelse(b>0,"+",""),b)
# R2<-bquote(R^2 == .(r2)) 
# 
# abline(0,1)
# abline(lm(Ebal_numerator~Ebal_denominator),col='grey',lty=2)
# mtext( lm_eq,side=3,line=-2,at=200,cex=0.9)
# mtext(R2,side=3,line=-3,at=200,cex=0.9)
# 
# # Do diurnal approach - applies equal weight to all times of day
# 
# # Find index of first day starting at 00:30
# ind <- which(Data_QAQC$min_local == 30 & Data_QAQC$hour_local == 0)
# is <- ind[1]
# 
# # Find index of last day ending at 00:00
# ind <- which(Data_QAQC$min_local == 00 & Data_QAQC$hour_local == 0)
# ie <- ind[length(ind)]
# 
# Ebal_numerator_diel <- Ebal_numerator[is:ie]
# Ebal_denominator_diel <- Ebal_denominator[is:ie]
# 
# Ebal_numerator_diel <- t(matrix(Ebal_numerator_diel, 48, length(Ebal_numerator[is:ie])/48))
# Ebal_denominator_diel <- t(matrix(Ebal_denominator_diel, 48, length(Ebal_numerator[is:ie])/48))
# 
# Ebal_numerator_diurn <- colMeans(x = Ebal_numerator_diel, na.rm = TRUE)
# Ebal_denominator_diurn = colMeans(x = Ebal_denominator_diel, na.rm = TRUE)
# 
# # Compute closure
# Eclosure = sum(Ebal_numerator_diurn)/sum(Ebal_denominator_diurn);
# mtext(paste('Diel Avg. Closure = ', round(Eclosure,2)),side=3,line=-4,at=200,cex=0.9)
```

```{r Save L2 output, echo=FALSE, warning=FALSE}
write.csv(Data_QAQC,paste('./flux_data/Young_L2','.csv',sep=''),row.names=FALSE)   
```

```{r Now export data for gap-filling and partitioning using REddyProc, echo=FALSE, warning=FALSE}
#Converting units for the right input file format
met$VPD_hPa <- met$VPD*10

# Create output file to use in REddyProc for ustar filtering - need all soil temp reps?
output <- cbind(met[M_start:M_end,match(c('year','DOY','hour','TA_1_1_1','SWIN_1_1_1','RH_1_1_1', 'VPD_hPa','TS_1_1_1','TS_2_1_1', 'TS_3_1_1'),names(met))], 
               Data_QAQC[F_start:F_end,match(c('co2_flux','ch4_flux','LE','H','u.'),names(Data_QAQC))])


# Reorder & rename columns
#output <- output[c("year", "jday", "hour_dec","co2_flux","ch4_flux","LE","H","SHORTWAVE_IN","AIR_TEMP_2M","SOIL_TEMP_5CM","SOIL_TEMP_10CM", "RH_2M","VPD_hPa","u.","WTH")]

#01/07/2020 - add reps for soil temp
output <- output[c("year", "DOY", "hour","co2_flux","ch4_flux","LE","H","SWIN_1_1_1","TA_1_1_1","TS_1_1_1","TS_2_1_1", 'TS_3_1_1', "RH_1_1_1","VPD_hPa","u.")]

names_output<-c('Year','DoY','Hour','NEE','FCH4','LE','H','Rg','Tair','Tsoil10cm_below','Tsoil10cm_above','Tsoil40cm_above','rH','VPD','Ustar')
names(output)<-names_output

#Adding the units row
UNITS<-list('-','-','-','umol_m-2_s-1','umol_m-2_s-1','Wm-2','Wm-2','Wm-2','degC','degC','degC','degC','%','hPa','ms-1')

output <- rbind(UNITS,output)

#Transforming missing values in -9999:
output[is.na(output)]<--9999

#Saving biomet file:
write.csv(met,paste('./met_data/Gapfilled_biomet','.csv',sep=''),row.names=FALSE)   
#Saving the file:
write.table(output, file = paste('./flux_data/REddyProc_input/for_gap_filling_partitioningYoung','.txt',sep=''),row.names=FALSE,sep='\t')   
```
